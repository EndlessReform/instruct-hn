{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embeddings for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (2.14.5)\n",
      "Requirement already satisfied: pandas in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: psycopg2 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (2.9.7)\n",
      "Requirement already satisfied: python-dotenv in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: torch in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: transformers in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (1.3.1)\n",
      "Requirement already satisfied: sqlalchemy in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (2.0.21)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /home/ritsuko/.local/lib/python3.10/site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: aiohttp in /home/ritsuko/.local/lib/python3.10/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (0.17.2)\n",
      "Requirement already satisfied: packaging in /home/ritsuko/.local/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ritsuko/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ritsuko/.local/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.5)\n",
      "Requirement already satisfied: lit in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ritsuko/.local/lib/python3.10/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from sqlalchemy) (2.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ritsuko/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ritsuko/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ritsuko/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ritsuko/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ritsuko/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ritsuko/.local/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/ritsuko/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets pandas psycopg2 python-dotenv torch transformers scikit-learn sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create base dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally you'll only have to do this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Make sure there's a .env file with PG_URL set to connection string!\n",
    "# Note for the unwary: make sure to restart the kernel if you change this.\n",
    "# Don't ask me how I know.\n",
    "engine = create_engine(os.getenv(\"PG_URL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM items WHERE title IS NOT NULL AND score >= 20;\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../datasets/raw-story-data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create title embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../datasets/raw-story-data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def choose_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.has_mps():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select bge base embeddings, which at time of writing are atop the embedding benchmark leaderboard and are a reasonable size compromise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/nlp/instruct-hn/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-base-en-v1.5')\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = choose_device()\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows that don't have a title\n",
    "df = df[df['title'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: principled ablations on document creation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and url columns into a single column\n",
    "# df['document'] = \"TITLE: \" + df['title'] + \"\\n\" + df['url'].fillna(\"\")\n",
    "df['document'] = df['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually embed the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(batch):\n",
    "    \"\"\"Generate embeddings for a batch of data.\"\"\"\n",
    "    inputs = tokenizer(batch['document'], padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # CLS pooling\n",
    "        embeddings = outputs[0][:, 0]\n",
    "        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "        \n",
    "    # Convert to numpy array on CPU\n",
    "    return {'embeddings': embeddings.cpu().numpy(), 'uid': batch['id']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mean_pooled_embeddings(batch):\n",
    "    \"\"\"Generate embeddings for a batch of data.\"\"\"\n",
    "    inputs = tokenizer(batch['document'], padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Exclude [CLS] and [SEP] tokens and compute mean pooling\n",
    "        embeddings = torch.mean(outputs[0][:, 1:-1, :], dim=1)\n",
    "        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "        \n",
    "    # Convert to numpy array on CPU\n",
    "    return {'embeddings': embeddings.cpu().numpy(), 'uid': batch['id']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 450733/450733 [01:17<00:00, 5846.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# generate embeddings\n",
    "dataset_with_embeddings = dataset.map(generate_embeddings, batched=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (4/4 shards): 100%|██████████| 450733/450733 [00:01<00:00, 346435.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndf = dataset_with_embeddings.to_pandas()\\ndf.to_parquet(\"../datasets/post-title-url-bge-mean_pooled.parquet\")\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_embeddings.save_to_disk(\"../datasets/post-title-bge-cls_pooled\")\n",
    "\"\"\"\n",
    "df = dataset_with_embeddings.to_pandas()\n",
    "df.to_parquet(\"../datasets/post-title-url-bge-mean_pooled.parquet\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
